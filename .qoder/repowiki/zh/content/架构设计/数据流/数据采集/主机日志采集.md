# 主机日志采集

<cite>
**本文档引用的文件**   
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py)
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py)
- [models.py](file://bklog/apps/log_databus/models.py)
- [constants.py](file://bklog/apps/log_databus/constants.py)
</cite>

## 目录
1. [采集器配置初始化流程](#采集器配置初始化流程)
2. [采集处理器通用逻辑](#采集处理器通用逻辑)
3. [采集配置数据模型](#采集配置数据模型)
4. [多路径日志采集配置](#多路径日志采集配置)
5. [采集任务生命周期](#采集任务生命周期)
6. [常见问题排查](#常见问题排查)

## 采集器配置初始化流程

主机日志采集器的配置初始化流程始于 `HostCollectorHandler` 类的 `update_or_create` 方法。该方法首先验证采集配置名称的唯一性，检查是否存在非法IP地址，并确保数据编码格式正确。初始化过程中，系统会创建或更新 `CollectorConfig` 记录，其中包含采集路径、过滤规则和编码设置等关键参数。

采集路径匹配通过 `params["paths"]` 字段实现，支持通配符和正则表达式匹配。文件读取策略采用增量读取方式，通过记录文件偏移量来避免重复采集。偏移量管理由节点管理（NodeMan）系统负责，存储在订阅配置中，确保采集任务重启后能从上次中断位置继续。

采集器配置的覆盖功能通过 `collector_config_overlay` 字段实现，允许在基础配置之上添加自定义参数。该字段在 `CollectorScenario` 基类的 `_handle_collector_config_overlay` 方法中被处理，将用户定义的配置合并到最终的采集器参数中。

**Section sources**
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L182-L371)
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L455-L462)
- [models.py](file://bklog/apps/log_databus/models.py#L121-L200)

## 采集处理器通用逻辑

`BaseCollectorHandler` 类定义了采集处理器的通用逻辑框架。该基类通过抽象方法 `_pre_start`、`_pre_stop` 和 `_pre_destroy` 定义了采集任务的生命周期钩子，`HostCollectorHandler` 类通过继承实现这些方法来处理主机采集特有的逻辑。

通用逻辑包括：采集任务状态管理、订阅配置同步、错误处理和日志记录。处理器通过 `get_subscription_status` 方法查询采集任务的执行状态，使用 `format_task_instance_status` 方法格式化任务实例状态数据。对于采集失败的实例，系统提供 `retry_target_nodes` 方法进行重试操作。

处理器还实现了字段映射功能，通过 `get_node_mapping` 方法将CMDB拓扑节点映射到具体的主机实例。该功能支持多种节点类型，包括主机实例、服务模板和集群模板，确保采集配置能准确应用到目标节点。

**Section sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L407-L480)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L801-L962)

## 采集配置数据模型

采集配置的核心数据模型为 `CollectorConfig`，其关键字段包括：

**采集配置核心字段**
- **collector_config_id**: 采集配置唯一标识
- **collector_config_name**: 采集配置名称
- **collector_config_name_en**: 采集配置英文名
- **target_nodes**: 采集目标节点列表
- **target_node_type**: 目标节点类型（INSTANCE、TOPO、SERVICE_TEMPLATE等）
- **data_encoding**: 日志字符编码
- **params**: 采集器参数配置
- **collector_config_overlay**: 采集器配置覆盖
- **extra_labels**: 额外字段添加

**采集状态与任务字段**
- **subscription_id**: 节点管理订阅ID
- **task_id_list**: 任务ID列表
- **is_active**: 采集配置是否激活
- **target_subscription_diff**: 与上一次采集订阅的差异

**存储与处理字段**
- **table_id**: 结果表ID
- **bk_data_id**: 数据平台Data ID
- **etl_config**: 清洗配置
- **storage_cluster_id**: 存储集群ID
- **retention**: 数据保留天数

这些字段共同构成了完整的采集配置数据模型，支持从配置创建到数据存储的完整流程。

**Section sources**
- [models.py](file://bklog/apps/log_databus/models.py#L101-L200)
- [constants.py](file://bklog/apps/log_databus/constants.py#L79-L105)

## 多路径日志采集配置

多路径日志采集通过 `params["paths"]` 字段配置，支持单个或多个日志文件路径。配置示例如下：

```python
params = {
    "paths": [
        "/var/log/app/*.log",
        "/opt/logs/service/*.txt",
        "/home/user/logs/**/*.log"
    ],
    "conditions": {
        "type": "separator",
        "separator": " ",
        "separator_regex": False,
        "fields": [
            {"field_index": 0, "field_name": "time"},
            {"field_index": 1, "field_name": "level"},
            {"field_index": 2, "field_name": "message"}
        ]
    },
    "encoding": "UTF-8",
    "collector_config_overlay": {
        "max_bytes_per_second": 1048576,
        "close_eof": True,
        "close_inactive": "5m"
    }
}
```

过滤规则通过 `conditions` 字段设置，支持分隔符和正则表达式两种模式。性能调优参数包括 `max_bytes_per_second`（每秒最大读取字节数）、`close_eof`（到达文件末尾是否关闭）和 `close_inactive`（文件非活跃多久后关闭）等。

采集器还支持排除文件配置，通过 `exclude_files` 字段指定不需要采集的文件模式，如 `*.tmp` 或 `*.bak` 文件。

**Section sources**
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L209-L237)
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L335-L342)

## 采集任务生命周期

采集任务从创建到部署的完整生命周期包括以下阶段：

1. **配置创建**：调用 `HostCollectorHandler.update_or_create` 方法创建采集配置
2. **订阅创建**：通过 `_update_or_create_subscription` 方法在节点管理中创建订阅
3. **任务执行**：调用 `_run_subscription_task` 方法触发采集任务
4. **状态监控**：通过 `get_subscription_status` 方法监控任务执行状态
5. **启动/停止**：使用 `start` 和 `stop` 方法控制采集任务的运行状态

与GSE Agent的交互主要通过节点管理API实现。当采集任务被触发时，节点管理会向目标主机的GSE Agent发送指令，部署并启动 `bkunifylogbeat` 采集插件。GSE Agent负责插件的生命周期管理，包括配置下发、进程控制和状态上报。

任务状态通过 `get_subscription_task_detail` 方法获取，该方法返回详细的执行日志，可用于故障排查。对于执行失败的任务，系统提供 `retry_target_nodes` 方法进行重试。

**Section sources**
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L87-L113)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L1283-L1305)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L547-L576)

## 常见问题排查

### 采集路径无效
当采集路径配置无效时，检查以下几点：
1. 确认路径在目标主机上实际存在
2. 验证路径格式是否正确，避免使用不支持的通配符
3. 检查路径是否包含特殊字符，需要进行适当转义

### 权限不足
权限问题通常表现为无法读取日志文件，解决方案包括：
1. 确认GSE Agent运行用户对日志文件有读取权限
2. 检查文件所属用户和组是否正确
3. 确保目录层级的执行权限（x权限）已正确设置

### 日志截断
日志截断问题可能由以下原因引起：
1. `close_eof` 配置为 `True`，导致采集器在到达文件末尾时关闭
2. `close_inactive` 时间设置过短，文件非活跃期间被关闭
3. 采集器性能不足，无法及时处理大量日志

通过调整采集器性能参数，如增加 `max_bytes_per_second` 值，可以缓解日志截断问题。同时，建议将 `close_eof` 设置为 `False`，确保采集器持续监控日志文件。

**Section sources**
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L403-L424)
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L1008-L1026)