# 日志采集服务

<cite>
**Referenced Files in This Document**   
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py)
- [k8s.py](file://bklog/apps/log_databus/handlers/collector/k8s.py)
- [bk_log_delimiter.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_delimiter.py)
- [bk_log_json.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_json.py)
- [bk_log_regexp.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_regexp.py)
- [transfer.py](file://bklog/apps/log_databus/handlers/etl/transfer.py)
- [models.py](file://bklog/apps/log_databus/models.py)
- [constants.py](file://bklog/apps/log_databus/constants.py)
</cite>

## 目录
1. [简介](#简介)
2. [项目结构](#项目结构)
3. [核心组件](#核心组件)
4. [架构概述](#架构概述)
5. [详细组件分析](#详细组件分析)
6. [依赖分析](#依赖分析)
7. [性能考虑](#性能考虑)
8. [故障排除指南](#故障排除指南)
9. [结论](#结论)
10. [附录](#附录) (如有必要)

## 简介
日志采集服务是蓝鲸日志平台的核心组件，作为数据总线负责从各种来源采集日志数据。该服务支持两种主要的采集模式：主机采集和Kubernetes（K8s）采集，能够灵活适应不同的部署环境。通过ETL（抽取、转换、加载）流程，服务能够对原始日志进行解析和清洗，支持分隔符、正则表达式和JSON格式等多种解析策略。清洗后的数据可以与BK-Data平台集成，实现数据的持久化存储。本文档将详细介绍从创建采集任务到数据入库的完整流程，包括配置管理、数据处理和错误处理机制。

## 项目结构
日志采集服务的代码主要位于`bklog/apps/log_databus`目录下，遵循模块化设计原则。核心功能被划分为采集器（collector）、ETL处理（etl）和存储（storage）三个主要模块。采集器模块负责管理采集配置和与节点管理系统的交互；ETL模块处理日志的解析和转换；存储模块则负责与Elasticsearch等后端存储系统的集成。这种分层架构使得系统易于维护和扩展。

```mermaid
graph TD
subgraph "采集器模块"
host[主机采集处理器]
k8s[K8s采集处理器]
base[采集器基类]
end
subgraph "ETL模块"
delimiter[分隔符解析]
json[JSON解析]
regexp[正则表达式解析]
transfer[ETL处理器]
end
subgraph "存储模块"
models[数据模型]
constants[常量定义]
end
host --> transfer
k8s --> transfer
delimiter --> transfer
json --> transfer
regexp --> transfer
transfer --> models
transfer --> constants
```

**Diagram sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py)
- [k8s.py](file://bklog/apps/log_databus/handlers/collector/k8s.py)
- [bk_log_delimiter.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_delimiter.py)
- [bk_log_json.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_json.py)
- [bk_log_regexp.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_regexp.py)
- [transfer.py](file://bklog/apps/log_databus/handlers/etl/transfer.py)

**Section sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L1-L200)
- [models.py](file://bklog/apps/log_databus/models.py#L1-L50)

## 核心组件

日志采集服务的核心组件包括采集器处理器、ETL解析器和数据模型。采集器处理器负责管理采集配置的生命周期，包括创建、启动、停止和删除。ETL解析器实现了多种日志解析策略，能够处理不同格式的日志数据。数据模型定义了采集配置和相关元数据的结构，确保数据的一致性和完整性。

**Section sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L124-L200)
- [models.py](file://bklog/apps/log_databus/models.py#L101-L200)

## 架构概述

日志采集服务采用分层架构，将采集、处理和存储功能解耦。采集层负责从目标系统收集日志数据；处理层对原始日志进行解析和清洗；存储层则将处理后的数据写入后端存储系统。这种架构设计提高了系统的可维护性和可扩展性。

```mermaid
graph TD
A[采集目标] --> B[采集器]
B --> C[ETL处理器]
C --> D[数据清洗]
D --> E[数据存储]
E --> F[Elasticsearch]
E --> G[BK-Data平台]
```

**Diagram sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L124-L200)
- [transfer.py](file://bklog/apps/log_databus/handlers/etl/transfer.py#L42-L268)

## 详细组件分析

### 采集器处理器分析
采集器处理器是日志采集服务的核心，负责管理采集配置的整个生命周期。它提供了统一的接口来处理主机和K8s环境下的采集任务。

#### 采集器基类
```mermaid
classDiagram
class CollectorHandler {
+collector_config_id int
+data CollectorConfig
+__init__(collector_config_id, data)
+start() bool
+stop() bool
+destroy() bool
+retrieve() dict
+custom_update() void
}
class HostCollectorHandler {
+FAST_CREATE_SERIALIZER Serializer
+FAST_UPDATE_SERIALIZER Serializer
+CREATE_SERIALIZER Serializer
+UPDATE_SERIALIZER Serializer
+_pre_start() void
+_pre_stop() void
+_pre_destroy() void
+update_or_create(params) dict
}
class K8sCollectorHandler {
+FAST_CREATE_SERIALIZER Serializer
+FAST_UPDATE_SERIALIZER Serializer
+CREATE_SERIALIZER Serializer
+UPDATE_SERIALIZER Serializer
+CONTAINER_CONFIG_FIELDS list
+_pre_start() void
+_pre_stop() void
+_pre_destroy() void
+update_container_config(data) dict
+create_container_config(data) dict
}
CollectorHandler <|-- HostCollectorHandler
CollectorHandler <|-- K8sCollectorHandler
```

**Diagram sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L124-L200)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L81-L200)
- [k8s.py](file://bklog/apps/log_databus/handlers/collector/k8s.py#L112-L200)

#### 采集流程
```mermaid
sequenceDiagram
participant 用户 as 用户
participant 采集器 as 采集器处理器
participant 节点管理 as 节点管理系统
participant 存储 as 存储系统
用户->>采集器 : 创建采集配置
采集器->>采集器 : 验证配置参数
采集器->>节点管理 : 创建订阅
节点管理-->>采集器 : 返回订阅ID
采集器->>存储 : 创建数据ID
存储-->>采集器 : 返回数据ID
采集器->>用户 : 返回成功响应
用户->>采集器 : 启动采集任务
采集器->>节点管理 : 启用订阅
节点管理-->>采集器 : 返回任务ID
采集器->>用户 : 返回任务状态
```

**Diagram sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L408-L441)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L87-L99)

### ETL解析器分析
ETL解析器负责对原始日志进行解析和转换，支持多种解析策略。

#### ETL解析策略
```mermaid
flowchart TD
Start([开始]) --> ValidateInput["验证输入参数"]
ValidateInput --> InputValid{"输入有效?"}
InputValid --> |否| ReturnError["返回错误响应"]
InputValid --> |是| ParseType{"解析类型?"}
ParseType --> |分隔符| ParseDelimiter["分隔符解析"]
ParseType --> |JSON| ParseJSON["JSON解析"]
ParseType --> |正则表达式| ParseRegexp["正则表达式解析"]
ParseDelimiter --> ProcessResult["处理解析结果"]
ParseJSON --> ProcessResult
ParseRegexp --> ProcessResult
ProcessResult --> CleanData["数据清洗"]
CleanData --> StoreData["数据存储"]
StoreData --> End([结束])
ReturnError --> End
```

**Diagram sources**
- [bk_log_delimiter.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_delimiter.py#L43-L71)
- [bk_log_json.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_json.py#L29-L40)
- [bk_log_regexp.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_regexp.py#L33-L49)

#### 数据模型
```mermaid
erDiagram
COLLECTOR_CONFIG {
int collector_config_id PK
string collector_config_name
string collector_config_name_en
int bk_biz_id
int bkdata_biz_id
string collector_scenario_id
string custom_type
string category_id
string target_object_type
string target_node_type
json target_nodes
json target_subscription_diff
text description
bool is_active
int data_link_id
int bk_data_id
string bk_data_name
string table_id
string bkbase_table_id
string processing_id
string etl_processor
string etl_config
int subscription_id
string task_id_list
int bkdata_data_id
int index_set_id
string data_encoding
json params
string itsm_ticket_sn
string itsm_ticket_status
bool can_use_independent_es_cluster
int collector_package_count
string collector_output_format
json collector_config_overlay
int storage_shards_nums
int storage_shards_size
int storage_replies
int bkdata_data_id_sync_times
string environment
string bcs_cluster_id
json extra_labels
bool add_pod_label
bool add_pod_annotation
bool yaml_config_enabled
text yaml_config
int rule_id
bool is_display
bigint log_group_id
bool is_nanos
bool enable_v4
}
```

**Diagram sources**
- [models.py](file://bklog/apps/log_databus/models.py#L101-L200)

**Section sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L124-L200)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L81-L200)
- [k8s.py](file://bklog/apps/log_databus/handlers/collector/k8s.py#L112-L200)
- [bk_log_delimiter.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_delimiter.py#L43-L71)
- [bk_log_json.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_json.py#L29-L40)
- [bk_log_regexp.py](file://bklog/apps/log_databus/handlers/etl_storage/bk_log_regexp.py#L33-L49)
- [transfer.py](file://bklog/apps/log_databus/handlers/etl/transfer.py#L42-L268)
- [models.py](file://bklog/apps/log_databus/models.py#L101-L200)
- [constants.py](file://bklog/apps/log_databus/constants.py#L377-L382)

## 依赖分析

日志采集服务依赖于多个外部系统和内部模块。主要依赖包括节点管理系统用于部署采集代理，BK-Data平台用于数据存储和分析，以及Elasticsearch用于日志的索引和查询。

```mermaid
graph TD
A[日志采集服务] --> B[节点管理系统]
A --> C[BK-Data平台]
A --> D[Elasticsearch]
A --> E[CMDB]
A --> F[API网关]
B --> G[主机]
C --> H[数据仓库]
D --> I[索引存储]
E --> J[业务拓扑]
F --> K[外部系统]
```

**Diagram sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L33-L35)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L26-L27)
- [k8s.py](file://bklog/apps/log_databus/handlers/collector/k8s.py#L31-L32)

**Section sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L33-L35)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L26-L27)
- [k8s.py](file://bklog/apps/log_databus/handlers/collector/k8s.py#L31-L32)

## 性能考虑

日志采集服务在设计时考虑了性能优化。通过批量处理和并发执行，系统能够高效地处理大量日志数据。ETL处理器支持并行解析，可以充分利用多核CPU的计算能力。此外，系统还实现了缓存机制，减少了对后端系统的重复查询。

## 故障排除指南

当采集任务出现故障时，可以通过以下步骤进行排查：
1. 检查采集配置是否正确
2. 验证目标主机或K8s集群的连接状态
3. 查看节点管理系统的任务日志
4. 检查ETL处理的错误日志
5. 验证存储系统的可用性

**Section sources**
- [base.py](file://bklog/apps/log_databus/handlers/collector/base.py#L114-L121)
- [host.py](file://bklog/apps/log_databus/handlers/collector/host.py#L547-L575)
- [k8s.py](file://bklog/apps/log_databus/handlers/collector/k8s.py#L548-L575)

## 结论

日志采集服务作为蓝鲸日志平台的核心组件，提供了一套完整的日志采集和处理解决方案。通过灵活的采集模式、强大的ETL功能和可靠的错误处理机制，服务能够满足各种复杂的日志管理需求。未来可以通过引入更智能的解析算法和优化性能来进一步提升服务的质量。