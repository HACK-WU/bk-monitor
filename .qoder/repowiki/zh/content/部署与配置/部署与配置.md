# Deployment and Configuration

<cite>
**Referenced Files in This Document**   
- [default.py](file://bkmonitor/config/default.py)
- [dev.py](file://bkmonitor/config/dev.py)
- [prod.py](file://bkmonitor/config/prod.py)
- [stag.py](file://bkmonitor/config/stag.py)
- [mysql.py](file://bkmonitor/config/tools/mysql.py)
- [redis.py](file://bkmonitor/config/tools/redis.py)
- [kafka.py](file://bkmonitor/config/tools/kafka.py)
- [rabbitmq.py](file://bkmonitor/config/tools/rabbitmq.py)
- [consul.py](file://bkmonitor/config/tools/consul.py)
- [elasticsearch.py](file://bkmonitor/config/tools/elasticsearch.py)
- [service.py](file://bkmonitor/config/tools/service.py)
- [transfer.py](file://bkmonitor/config/tools/transfer.py)
- [license.py](file://bkmonitor/config/tools/license.py)
- [influxdb_proxy.py](file://bkmonitor/config/tools/influxdb_proxy.py)
- [config.py](file://bkmonitor/config/celery/config.py)
- [web.py](file://bkmonitor/config/role/web.py)
- [worker.py](file://bkmonitor/config/role/worker.py)
- [api.py](file://bkmonitor/config/role/api.py)
- [environment.py](file://bkmonitor/config/tools/environment.py)
- [check_bcs_cluster_status.py](file://bkmonitor/metadata/management/commands/check_bcs_cluster_status.py) - *Updated in recent commit*
- [sync_bcs_space.py](file://bkmonitor/metadata/management/commands/sync_bcs_space.py) - *Added in recent commit*
- [README_BCS_CLUSTER_CHECK_ENHANCED.md](file://README_BCS_CLUSTER_CHECK_ENHANCED.md) - *Added in recent commit*
- [pyproject.toml](file://bkmonitor/pyproject.toml) - *Updated in recent commit*
- [uv.lock](file://bkmonitor/uv.lock) - *Updated in recent commit*
</cite>

## Update Summary
**Changes Made**   
- Updated the "Update Summary" section to reflect new Python dependency updates
- Added information about Python package management updates affecting the deployment process
- Updated the list of referenced files to include pyproject.toml and uv.lock
- Added new section on AI Agent Configuration for the updated SDK
- Maintained all existing BCS cluster check and deployment checklist content

## Table of Contents

1. [Introduction](#introduction)
2. [Project Structure](#project-structure)
3. [Environment Configuration Management](#environment-configuration-management)
4. [Key Service Configuration](#key-service-configuration)
5. [Docker and Traditional Deployment Solutions](#docker-and-traditional-deployment-solutions)
6. [Service Dependencies and Startup Order](#service-dependencies-and-startup-order)
7. [Performance Tuning and Resource Planning](#performance-tuning-and-resource-planning)
8. [Health Checks and Operations Management](#health-checks-and-operations-management)
9. [Enhanced BCS Cluster Check Process](#enhanced-bcs-cluster-check-process)
10. [Deployment Checklist and Troubleshooting](#deployment-checklist-and-troubleshooting)
11. [AI Agent Configuration](#ai-agent-configuration)

## Introduction

This guide aims to provide operations personnel with complete deployment and configuration instructions for the **bk-monitor** system in production environments. The document details configuration differences for development, testing, pre-production, and production environments, explains the structure of core configuration files and key parameters, and provides detailed steps for both Docker and traditional deployment. Additionally, this document covers service dependencies, performance tuning recommendations, health check configuration, and troubleshooting guidance to ensure the system runs stably and efficiently.

## Project Structure

The `bk-monitor` project adopts a modular design with the following main structure:

```
bkmonitor/
├── config/                    # Core configuration directory
├── bin/                       # System management scripts
├── api/                       # External API interface definitions
├── alarm_backends/            # Alert core processing logic
├── apm/                       # Application performance monitoring module
├── bk_dataview/               # Data view service
├── bkm_ipchooser/             # IP selector service
├── core/                      # Core framework and tools
├── docs/                      # Documentation
├── scripts/                   # Automation scripts
├── support-files/             # Support files (e.g., Supervisor configuration)
├── Dockerfile                 # Docker build file
├── manage.py                  # Django management script
└── settings.py                # Django main configuration entry
```

**Section sources**
- [project_structure](file://workspace)

## Environment Configuration Management

The system implements multi-environment management through configuration files in the `config` directory, using an inheritance and override pattern.

### Configuration File Hierarchy

The system dynamically loads configurations based on the `DJANGO_CONF_MODULE` environment variable. Its value is typically `config.web.{environment}.{platform}`, for example, `config.web.prod.linux`.

``mermaid
graph TD
A[default.py] --> B[dev.py]
A --> C[stag.py]
A --> D[prod.py]
B --> E[Final Development Environment Configuration]
C --> F[Final Pre-production Environment Configuration]
D --> G[Final Production Environment Configuration]
```

**Diagram sources**
- [default.py](file://bkmonitor/config/default.py)
- [dev.py](file://bkmonitor/config/dev.py)
- [stag.py](file://bkmonitor/config/stag.py)
- [prod.py](file://bkmonitor/config/prod.py)

### Environment Differences Analysis

| Configuration Item | Development Environment (dev.py) | Production Environment (prod.py) |
| :--- | :--- | :--- |
| **Run Mode** | `RUN_MODE = "DEVELOP"` | `RUN_MODE = "PRODUCT"` |
| **Debug Mode** | `DEBUG = True` | `DEBUG = False` |
| **Database** | Local MySQL (`localhost:3306`) | Remote MySQL configured via environment variables |
| **Message Queue** | Redis (`localhost:6379`) | RabbitMQ (configured via environment variables) |
| **Static Resources** | Loaded from `webpack` directory | Loaded from `STATIC_ROOT` directory |
| **Cross-Origin** | `CORS_ALLOW_ALL_ORIGINS = True` | `CORS_ALLOW_ALL_ORIGINS = True` (also supported in production) |

**Section sources**
- [default.py](file://bkmonitor/config/default.py#L1-L200)
- [dev.py](file://bkmonitor/config/dev.py#L1-L75)
- [prod.py](file://bkmonitor/config/prod.py#L1-L24)
- [stag.py](file://bkmonitor/config/stag.py#L1-L26)

### Environment Variable Management

The `environment.py` file is responsible for parsing environment variables to determine the current runtime environment.

```python
# config/tools/environment.py
if "BKPAAS_ENVIRONMENT" in os.environ:
    PAAS_VERSION = "V3"  # BlueKing PaaS V3
elif "BK_ENV" in os.environ:
    PAAS_VERSION = "V2"  # BlueKing PaaS V2
else:
    PAAS_VERSION = ""

# Map PaaS version to environment
ENVIRONMENT = {
    "dev": "development",
    "stag": "testing",
    "prod": "production",
}.get(PAAS_V3_ENVIRONMENT)
```

**Section sources**
- [environment.py](file://bkmonitor/config/tools/environment.py#L1-L82)

## Key Service Configuration

### Database Connection (MySQL)

The system uses the `mysql.py` utility function to obtain connection information for different databases.

```python
# config/tools/mysql.py
def get_backend_mysql_settings():
    # Get backend database settings, prioritizing environment variables
    name = os.getenv("BK_MONITOR_MYSQL_NAME") or name
    host = os.getenv("BK_MONITOR_MYSQL_HOST") or host
    port = int(os.getenv("BK_MONITOR_MYSQL_PORT") or port)
    user = os.getenv("BK_MONITOR_MYSQL_USER") or user
    password = os.getenv("BK_MONITOR_MYSQL_PASSWORD") or password
    return name, host, port, user, password
```

**Configuration Parameter Description**:
- `BK_MONITOR_MYSQL_HOST`: Database host address
- `BK_MONITOR_MYSQL_PORT`: Database port
- `BK_MONITOR_MYSQL_NAME`: Database name
- `BK_MONITOR_MYSQL_USER`: Database username
- `BK_MONITOR_MYSQL_PASSWORD`: Database password

**Section sources**
- [mysql.py](file://bkmonitor/config/tools/mysql.py#L1-L79)

### Cache Settings (Redis)

The `redis.py` file determines whether to use standalone mode or sentinel mode based on service role (`ROLE`) and environment (`ENVIRONMENT`).

```python
# config/tools/redis.py
def get_redis_settings():
    if ROLE in ["worker", "api"]:
        mode = os.environ.get("BK_MONITOR_REDIS_MODE", "sentinel")  # Default to sentinel mode
        cache_backend_type = {"sentinel": "SentinelRedisCache", "standalone": "RedisCache"}.get(mode)
    else:
        cache_backend_type = "RedisCache"  # Web role defaults to standalone
    return cache_backend_type, host, port, password, master_name, sentinel_password
```

**Configuration Parameter Description**:
- `BK_MONITOR_REDIS_MODE`: Redis mode (`sentinel` or `standalone`)
- `BK_MONITOR_REDIS_HOST`: Redis host address
- `BK_MONITOR_REDIS_PORT`: Redis port
- `BK_MONITOR_REDIS_SENTINEL_HOST`: Redis sentinel host address
- `BK_MONITOR_REDIS_SENTINEL_PORT`: Redis sentinel port
- `BK_MONITOR_REDIS_PASSWORD`: Redis password

**Section sources**
- [redis.py](file://bkmonitor/config/tools/redis.py#L1-L85)

### Message Queue Configuration (Kafka & RabbitMQ)

#### Kafka
Used for data stream processing with simple configuration.

```python
# config/tools/kafka.py
def get_kafka_settings():
    host = [os.environ.get("BK_MONITOR_KAFKA_HOST", "kafka.service.consul")]
    port = int(os.environ.get("BK_MONITOR_KAFKA_PORT", 9092))
    return host, port
```

#### RabbitMQ
Used as the Celery task queue.

```python
# config/tools/rabbitmq.py
def get_rabbitmq_settings(app_code: str, backend=False):
    if backend:
        # Backend services use independent configuration
        host = os.environ.get("BK_MONITOR_RABBITMQ_HOST", "rabbitmq.service.consul")
        vhost = os.environ.get("BK_MONITOR_RABBITMQ_VHOST", app_code)
        user = os.environ.get("BK_MONITOR_RABBITMQ_USERNAME", app_code)
        password = os.environ.get("BK_MONITOR_RABBITMQ_PASSWORD", "")
    # ... Construct broker_url
    return host, port, vhost, user, password, broker_url
```

**Configuration Parameter Description**:
- `BK_MONITOR_KAFKA_HOST`: Kafka host address
- `BK_MONITOR_KAFKA_PORT`: Kafka port
- `BK_MONITOR_RABBITMQ_HOST`: RabbitMQ host address
- `BK_MONITOR_RABBITMQ_VHOST`: RabbitMQ virtual host
- `BK_MONITOR_RABBITMQ_USERNAME`: RabbitMQ username
- `BK_MONITOR_RABBITMQ_PASSWORD`: RabbitMQ password

**Section sources**
- [kafka.py](file://bkmonitor/config/tools/kafka.py#L1-L20)
- [rabbitmq.py](file://bkmonitor/config/tools/rabbitmq.py#L1-L46)

### Other Key Services

| Service | Configuration File | Key Environment Variables |
| :--- | :--- | :--- |
| **Consul** | `consul.py` | `BK_MONITOR_CONSUL_HOST`, `BK_MONITOR_CONSUL_PORT` |
| **Elasticsearch** | `elasticsearch.py` | `BKAPP_FTA_ES7_HOST`, `BKAPP_FTA_ES7_REST_PORT` |
| **Data Transfer Service** | `transfer.py` | `BK_TRANSFER_HOST`, `BK_TRANSFER_HTTP_PORT` |
| **License Service** | `license.py` | `BK_LICENSE_HOST`, `BK_LICENSE_PORT` |
| **InfluxDB Proxy** | `influxdb_proxy.py` | `BK_INFLUXDB_PROXY_HOST`, `BK_INFLUXDB_PROXY_PORT` |
| **Third-party Service URLs** | `service.py` | `BKPAAS_SERVICE_ADDRESSES_BKSAAS` |

**Section sources**
- [consul.py](file://bkmonitor/config/tools/consul.py#L1-L36)
- [elasticsearch.py](file://bkmonitor/config/tools/elasticsearch.py#L1-L31)
- [transfer.py](file://bkmonitor/config/tools/transfer.py#L1-L20)
- [license.py](file://bkmonitor/config/tools/license.py#L1-L18)
- [influxdb_proxy.py](file://bkmonitor/config/tools/influxdb_proxy.py#L1-L20)
- [service.py](file://bkmonitor/config/tools/service.py#L1-L43)

### Celery Task Queue Configuration

The `celery/config.py` defines global Celery configurations and scheduled tasks.

```python
# config/celery/config.py
class Config:
    broker_url = celery_broker_url  # From RabbitMQ configuration
    result_backend = "django_celery_results.backends:DatabaseBackend"
    beat_scheduler = "monitor.schedulers.MonitorDatabaseScheduler"
    timezone = "Asia/Shanghai"
    task_always_eager = True if settings.ROLE == "api" else False  # API service does not execute tasks asynchronously
```

**Scheduled Task Examples**:
- `update_metric_list`: Executes every minute to update the metric list.
- `soft_delete_expired_shields`: Executes at 2:00 AM daily to clean up expired shielding rules.

**Section sources**
- [config.py](file://bkmonitor/config/celery/config.py#L1-L123)

## Docker and Traditional Deployment Solutions

### Docker Deployment Solution

1.  **Build Image**:
    ```bash
    docker build -t bk-monitor:latest .
    ```

2.  **Prepare Environment Variable File** (`env.prod`):
    ```env
    DJANGO_CONF_MODULE=config.web.prod.linux
    BK_MONITOR_MYSQL_HOST=10.0.0.10
    BK_MONITOR_MYSQL_PASSWORD=your_password
    BK_MONITOR_REDIS_MODE=sentinel
    BK_MONITOR_REDIS_SENTINEL_HOST=10.0.0.11
    # ... Other necessary environment variables
    ```

3.  **Start Container**:
    ```bash
    docker run -d --env-file env.prod --name bk-monitor bk-monitor:latest
    ```

### Traditional Deployment Solution

1.  **Install Dependencies**:
    ```bash
    pip install -r requirements.txt
    ```

2.  **Configure Environment Variables**:
    Set all necessary environment variables in the system environment or `.env` file.

3.  **Database Migration**:
    ```bash
    python manage.py migrate
    ```

4.  **Collect Static Files**:
    ```bash
    python manage.py collectstatic --noinput
    ```

5.  **Start Services**:
    - **Web Service**: `python manage.py runserver 0.0.0.0:8000`
    - **Worker Service**: `celery -A settings worker -l info -Q celery`
    - **Beat Service**: `celery -A settings beat -l info`

**Section sources**
- [Dockerfile](file://Dockerfile)
- [manage.py](file://manage.py)
- [bin/manage.sh](file://bkmonitor/bin/manage.sh)

## Service Dependencies and Startup Order

The system consists of multiple roles (`ROLE`) with clear dependency relationships.

``mermaid
graph LR
A[Consul] --> B[MySQL]
A --> C[Redis]
A --> D[RabbitMQ]
A --> E[Kafka]
B --> F[Web Service]
C --> F
D --> G[Worker Service]
D --> H[Beat Service]
E --> G
F --> G
G --> I[Alert Processing]
H --> J[Scheduled Tasks]
```

**Startup Order Requirements**:
1.  **Infrastructure**: First start external dependency services such as Consul, MySQL, Redis, RabbitMQ, and Kafka.
2.  **Web Service**: Start the service with `ROLE=web` to provide APIs and web interface.
3.  **Worker Service**: Start the service with `ROLE=worker` to process asynchronous tasks and alerts.
4.  **Beat Service**: Start the service with `ROLE=api` (which typically also handles Beat) to schedule periodic tasks.
5.  **BCS Cluster Synchronization**: Execute the `python manage.py sync_bcs_space` command to synchronize BCS project space data.

**Section sources**
- [web.py](file://bkmonitor/config/role/web.py)
- [worker.py](file://bkmonitor/config/role/worker.py)
- [api.py](file://bkmonitor/config/role/api.py)
- [sync_bcs_space.py](file://bkmonitor/metadata/management/commands/sync_bcs_space.py)

## Performance Tuning and Resource Planning

### Performance Tuning Recommendations

- **Database**:
  - Create appropriate indexes on core tables in the `alarm_backends` module (e.g., alert record tables).
  - Regularly archive and clean up historical data.
- **Redis**:
  - Monitor Redis memory usage to avoid out-of-memory issues.
  - For high-concurrency scenarios, recommend using sentinel mode or cluster mode.
- **Celery**:
  - Adjust the `CELERYD_CONCURRENCY` parameter based on task load.
  - Configure different queues for different types of tasks to prevent long tasks from blocking short tasks.
- **Django**:
  - Enable `whitenoise` for efficient static file serving.
  - Disable `DEBUG` mode in production environments.

### Resource Planning Guidance

- **CPU**: Recommend at least 4 cores, with Worker services having higher CPU requirements.
- **Memory**: Recommend at least 8GB, with Redis and database being the primary memory consumers.
- **Storage**: Primarily for database and logs; plan based on data volume and retention period.
- **Network**: Ensure network connectivity with monitored hosts, GSE, CMDB, and other services.

**Section sources**
- [default.py](file://bkmonitor/config/default.py#L1-L200)
- [config.py](file://bkmonitor/config/celery/config.py#L1-L123)

## Health Checks and Operations Management

### Health Check Configuration

The system has a built-in health check endpoint that can be accessed via the `/healthz/` path. This endpoint verifies the connection status of critical components such as the database, Redis, and Consul.

### Operations Management Configuration

- **Log Management**: Log configuration is provided by `blueapps.conf.log`, and the log level can be adjusted via the `LOG_LEVEL` environment variable.
- **Self-Monitoring**: It is recommended to include the `bk-monitor` service itself in monitoring, monitoring its process status, ports, API response times, etc.
- **Configuration Hot Updates**: Achieve dynamic updates of some configurations through Consul without restarting the service.

**Section sources**
- [default.py](file://bkmonitor/config/default.py#L1-L200)
- [environment.py](file://bkmonitor/config/tools/environment.py#L1-L82)

## Enhanced BCS Cluster Check Process

### BCS Cluster Status Check Command

The `check_bcs_cluster_status` command is a core tool for detecting the operational status of BCS clusters throughout the monitoring association chain. This command has been optimized and enhanced to provide more comprehensive check items.

```python
# bkmonitor/metadata/management/commands/check_bcs_cluster_status.py
class Command(BaseCommand):
    """
    BCS Cluster Association Status Detection Command
    
    Detects the operational status of a specified cluster ID throughout the monitoring association chain, including:
    1. Database record status check - Verify cluster basic information and configuration
    2. BCS API connectivity test - Test communication with BCS service
    3. Kubernetes cluster connection test - Verify K8s API availability
    4. Data source configuration validation - Check monitoring data source configuration
    5. Monitoring resource status check - ServiceMonitor and PodMonitor status
    6. Data storage chain check - InfluxDB, ES, and other storage cluster status
    7. Consul configuration check - Verify configuration center data synchronization
    8. Data collection configuration check - Replacement configuration and metric group configuration
    9. Federated cluster relationship check - Federated cluster topology and namespace mapping
    10. Data routing configuration check - Transfer cluster and MQ configuration
    11. Cluster resource usage check - Node, Pod status, and resource usage
    12. Cluster initialization resource check - EventGroup, TimeSeriesGroup, SpaceDataSource association status
    13. bk-collector configuration check - DaemonSet deployment status, Pod runtime status, configuration file integrity
    14. Cluster business permission check - SpaceDataSource authorization, space_uid configuration, bk_biz_id configuration
    """
```

**Usage**:
```bash
# Basic usage
python manage.py check_bcs_cluster_status --cluster-id BCS-K8S-00001

# JSON format output
python manage.py check_bcs_cluster_status --cluster-id BCS-K8S-00001 --format json

# Set timeout
python manage.py check_bcs_cluster_status --cluster-id BCS-K8S-00001 --timeout 60
```

**Check Item Description**:
- **Database Record Check**: Verify the completeness of cluster basic information and configuration in the database.
- **BCS API Connectivity Test**: Test communication with the BCS service.
- **Kubernetes Cluster Connection Test**: Verify the availability of the K8s API and node health status.
- **Data Source Configuration Validation**: Check the correctness of monitoring data source configuration.
- **Monitoring Resource Status Check**: Confirm the status of monitoring resources such as ServiceMonitor and PodMonitor.
- **Data Storage Chain Check**: Verify the connection status of storage clusters such as InfluxDB and ES.
- **Consul Configuration Check**: Ensure data synchronization in the configuration center is normal.
- **Data Collection Configuration Check**: Check the validity of replacement configuration and metric group configuration.
- **Federated Cluster Relationship Check**: Verify the topology structure and namespace mapping of federated clusters.
- **Data Routing Configuration Check**: Confirm the routing configuration of Transfer clusters and MQ.
- **Cluster Resource Usage Check**: Monitor resource usage of nodes and Pods.
- **Cluster Initialization Resource Check**: Verify the status of initialization resources such as EventGroup and TimeSeriesGroup.
- **bk-collector Configuration Check**: Check DaemonSet deployment, Pod runtime status, and configuration file integrity.
- **Cluster Business Permission Check**: Verify SpaceDataSource authorization, space_uid, and bk_biz_id configuration.

**Section sources**
- [check_bcs_cluster_status.py](file://bkmonitor/metadata/management/commands/check_bcs_cluster_status.py)
- [README_BCS_CLUSTER_CHECK_ENHANCED.md](file://README_BCS_CLUSTER_CHECK_ENHANCED.md)

## Deployment Checklist and Troubleshooting

### Deployment Checklist

- [ ] All external dependency services (MySQL, Redis, RabbitMQ, Kafka, Consul) are running normally.
- [ ] The environment variable `DJANGO_CONF_MODULE` has been correctly set.
- [ ] Database connection information (host, port, username, password) has been provided via environment variables.
- [ ] Message queue (RabbitMQ) connection information has been configured.
- [ ] The `migrate` command has been executed to synchronize the database.
- [ ] The `collectstatic` command has been executed to collect static files.
- [ ] Web, Worker, and Beat services have been started in order.
- [ ] The `python manage.py sync_bcs_space` command has been executed to synchronize BCS project space data.
- [ ] The `python manage.py check_bcs_cluster_status --cluster-id <cluster_id>` command has been used to verify BCS cluster status.

### Troubleshooting Guide

- **Service Fails to Start**:
  1.  Check log files to locate error messages.
  2.  Confirm whether `DJANGO_CONF_MODULE` points to the correct configuration file.
  3.  Check if dependency services such as database and Redis are reachable.
- **API Returns 500 Error**:
  1.  Check Django logs to view specific exception stack traces.
  2.  Confirm whether the database connection is normal.
- **Alerts Not Triggering**:
  1.  Check if the Worker service is running normally.
  2.  Check if there is a backlog in the Kafka message queue.
  3.  Check if the alert policy configuration is correct.
- **Page Loads Slowly**:
  1.  Check if Redis cache is effective.
  2.  Check if there are slow queries in the database.
- **BCS Cluster Monitoring Abnormal**:
  1.  Use the `python manage.py check_bcs_cluster_status --cluster-id <cluster_id>` command to check cluster status.
  2.  Check the deployment status and Pod runtime of the `bk-collector` DaemonSet.
  3.  Verify data source configuration and Consul configuration.
  4.  Confirm BCS API Token and cloud region ID configuration.

**Section sources**
- [default.py](file://bkmonitor/config/default.py#L1-L200)
- [dev.py](file://bkmonitor/config/dev.py#L1-L75)
- [prod.py](file://bkmonitor/config/prod.py#L1-L24)
- [check_bcs_cluster_status.py](file://bkmonitor/metadata/management/commands/check_bcs_cluster_status.py)
- [sync_bcs_space.py](file://bkmonitor/metadata/management/commands/sync_bcs_space.py)

## AI Agent Configuration

### AI Agent SDK Configuration

The recent update upgraded the AIAgents SDK version to resolve GPTOSS text rendering issues. This requires updates to the deployment environment dependencies.

```toml
# bkmonitor/pyproject.toml
[tool.poetry.dependencies]
aidev-agent = "^1.2.0"  # Updated version for GPTOSS text rendering fix
```

**Configuration Parameters**:
- `AIDEV_AGENT_APP_CODE`: Application code for AIDev agent authentication
- `AIDEV_AGENT_APP_SECRET`: Application secret for AIDev agent authentication
- `AIDEV_API_BASE_URL`: Base URL for AIDev API services
- `AIDEV_AGENT_LLM_DEFAULT_TEMPERATURE`: Default temperature setting for LLM responses

**Section sources**
- [pyproject.toml](file://bkmonitor/pyproject.toml)
- [uv.lock](file://bkmonitor/uv.lock)
- [settings.py](file://bkmonitor/settings.py)
- [aidev_interface.py](file://ai_agent/core/aidev_interface.py)
- [resources.py](file://bkmonitor/ai_whale/resources/resources.py)